{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffa3f5cc-2823-47a4-9cb0-050cb70a0d60",
   "metadata": {},
   "source": [
    "# Reference Data Creation\n",
    "Here we will create the reference data for use in our NannyML test notebooks.\n",
    "First we will create the data for the scoring script test. This will be 'full' validation reference data, meaning it will be comprised of all five validation cohorts (to try and replecate how it would be implemented in production).\n",
    "Then we will create reference data for the validation test that will comprise of the first three validation cohorts. The reason for this is that we can use the final two cohorts as analysis data to see how the performance estimation works.\n",
    "Here we will also create pickled drift artefacts for use in the previously mentioned tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea1c78ba-6d15-4b8e-81fd-9fbab1ff40d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import time\n",
    "import matplotlib.pyplot as plt;\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "import os\n",
    "import sys\n",
    "import gcsfs\n",
    "sys.path.append(os.path.abspath(\"/home/jupyter/POM-feature-drift\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7fdb18-3967-4036-a076-433c0be420b5",
   "metadata": {},
   "source": [
    "# Scoring Script Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7327e035-106f-4625-b803-c2384feff984",
   "metadata": {},
   "source": [
    "## TA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87d5de7e-0c37-4700-9aba-5cc7c9593636",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_cohorts = ['202045-202052', '202053-202107', '202108-202111', '202116-202119', '292124-202127']\n",
    "for treatment in ['nt', 'low', 'medium', 'high']:\n",
    "    df = pd.DataFrame()\n",
    "    for cohort in validation_cohorts:\n",
    "        gcs_path = f'gs://andrew-pom/Revenue/ta_step_up_{treatment}_v2_{cohort}_oot.csv'\n",
    "        cohort_df = pd.read_csv(gcs_path, low_memory = False)\n",
    "        df = pd.concat([df, cohort_df])\n",
    "\n",
    "    dates = []\n",
    "    for index in df.ind:\n",
    "        dates.append(index.split('-')[0])\n",
    "\n",
    "    timestamps = []\n",
    "    for i, date in enumerate(dates):\n",
    "        timestamps.append(pd.to_datetime(str(dates[i]) + '-0', format = '%Y%W-%w'))\n",
    "    df['timestamp'] = timestamps\n",
    "\n",
    "    df.drop(columns = ['ind', 'xgb_preds', 'xgb_proba', 'logr_preds', 'logr_proba'], inplace = True)\n",
    "    df.rename(columns = {'lgbm_preds': 'pred_ta', 'lgbm_proba': 'pred_proba_ta'}, inplace = True)\n",
    "    df.sort_values(by = 'timestamp', inplace = True)\n",
    "    \n",
    "    df.to_csv(f'ta_{treatment}_reference_full.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f45c406-0b7a-486c-989d-e2a57a8fd954",
   "metadata": {},
   "source": [
    "## ARPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d77bcaf-f903-4547-a0e5-d04997338690",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_cohorts = ['202045-202052', '202053-202107', '202108-202111', '202116-202119', '292124-202127']\n",
    "for treatment in ['nt', 'low', 'medium', 'high']:\n",
    "    df = pd.DataFrame()\n",
    "    for cohort in validation_cohorts:\n",
    "        gcs_path = f'gs://andrew-pom/Revenue/revenue_step_up_{treatment}_6m_v3_{cohort}_oot.csv'\n",
    "        cohort_df = pd.read_csv(gcs_path, low_memory = False)\n",
    "        df = pd.concat([df, cohort_df])\n",
    "\n",
    "    dates = []\n",
    "    for index in df.ind:\n",
    "        dates.append(index.split('-')[0])\n",
    "\n",
    "    timestamps = []\n",
    "    for i, date in enumerate(dates):\n",
    "        timestamps.append(pd.to_datetime(str(dates[i]) + '-0', format = '%Y%W-%w'))\n",
    "    df['timestamp'] = timestamps\n",
    "\n",
    "    df.drop(columns = ['ind', 'xgbr_preds', 'linr_preds'], inplace = True)\n",
    "    df.rename(columns = {'lgbmr_preds': 'pred_arpu'}, inplace = True)\n",
    "    df.sort_values(by = 'timestamp', inplace = True)\n",
    "    \n",
    "    df.to_csv(f'arpu_{treatment}_reference_full.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e77ef7-3e9b-42a7-beab-0d195ba0b4d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "local-python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
